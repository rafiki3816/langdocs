#!/usr/bin/env python3
"""
LangChain RAG ì±—ë´‡ - ê°„ë‹¨í•œ ì‹¤í–‰ íŒŒì¼
"""

import os
import sys
import argparse
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='LangChain RAG ì±—ë´‡')
    parser.add_argument('--mode', choices=['chat', 'collect', 'evaluate', 'web'],
                       default='chat', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--question', type=str, help='ë‹¨ì¼ ì§ˆë¬¸ (chat ëª¨ë“œ)')
    parser.add_argument('--urls', nargs='+', help='ìˆ˜ì§‘í•  URL ëª©ë¡ (collect ëª¨ë“œ)')

    args = parser.parse_args()

    print("\nğŸ¤– LangChain RAG ì±—ë´‡ v1.0")
    print("=" * 50)

    if args.mode == 'chat':
        # ì±„íŒ… ëª¨ë“œ
        from llm import get_llm
        from vector_database import VectorDatabase
        from retriever import HybridRetriever

        print("ì±„íŒ… ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        # LLM ì´ˆê¸°í™”
        llm = get_llm()

        # ë²¡í„° DB ì´ˆê¸°í™”
        vdb = VectorDatabase()
        vdb.init_vectorstore()

        # Retriever ì´ˆê¸°í™”
        retriever = HybridRetriever(vdb)

        if args.question:
            # ë‹¨ì¼ ì§ˆë¬¸ ì²˜ë¦¬
            print(f"\nì§ˆë¬¸: {args.question}")

            # ë¬¸ì„œ ê²€ìƒ‰
            docs = retriever.search(args.question, k=3)

            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = "\n\n".join([doc.page_content[:500] for doc in docs])

            # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
            prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {args.question}

ë‹µë³€:"""

            response = llm.invoke(prompt)
            print(f"\në‹µë³€: {response.content if hasattr(response, 'content') else response}")

        else:
            # ëŒ€í™”í˜• ëª¨ë“œ
            print("\nëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

            while True:
                question = input("ì§ˆë¬¸> ").strip()

                if question.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                    print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                if not question:
                    continue

                # ë¬¸ì„œ ê²€ìƒ‰
                docs = retriever.search(question, k=3)

                # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                context = "\n\n".join([doc.page_content[:500] for doc in docs])

                # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
                prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

                response = llm.invoke(prompt)
                print(f"\në‹µë³€: {response.content if hasattr(response, 'content') else response}\n")

    elif args.mode == 'collect':
        # ë¬¸ì„œ ìˆ˜ì§‘ ëª¨ë“œ
        from data_collector import LangChainDataCollector

        print("ë¬¸ì„œ ìˆ˜ì§‘ ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        collector = LangChainDataCollector()

        if args.urls:
            urls = args.urls
        else:
            urls = collector.get_sample_urls()[:5]

        print(f"ìˆ˜ì§‘í•  URL: {len(urls)}ê°œ")
        documents = collector.collect_documents(urls=urls, max_pages=len(urls))

        if documents:
            print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ìˆ˜ì§‘ ì™„ë£Œ")

            # ë²¡í„° DBì— ì €ì¥
            from vector_database import VectorDatabase
            vdb = VectorDatabase()
            vdb.init_vectorstore()

            # ì²­í¬ ë¶„í• 
            chunked_docs = collector.chunk_documents(documents)

            # ë²¡í„° DBì— ì¶”ê°€
            vdb.add_documents(chunked_docs)
            print(f"âœ… {len(chunked_docs)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
        else:
            print("âŒ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨")

    elif args.mode == 'evaluate':
        # í‰ê°€ ëª¨ë“œ
        print("í‰ê°€ ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_questions = [
            "LangChainì´ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì²´ì¸(Chain)ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì—ì´ì „íŠ¸(Agent)ëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?"
        ]

        from llm import get_llm
        from vector_database import VectorDatabase
        from retriever import HybridRetriever
        import time

        llm = get_llm()
        vdb = VectorDatabase()
        vdb.init_vectorstore()
        retriever = HybridRetriever(vdb)

        print(f"\n{len(test_questions)}ê°œ ì§ˆë¬¸ í‰ê°€ ì¤‘...")

        for i, question in enumerate(test_questions, 1):
            print(f"\n[{i}/{len(test_questions)}] {question}")

            start_time = time.time()

            # ë¬¸ì„œ ê²€ìƒ‰
            docs = retriever.search(question, k=3)

            # ë‹µë³€ ìƒì„±
            if docs:
                context = "\n\n".join([doc.page_content[:300] for doc in docs])
                prompt = f"ì»¨í…ìŠ¤íŠ¸: {context}\n\nì§ˆë¬¸: {question}\n\në‹µë³€:"
                response = llm.invoke(prompt)
                answer = response.content if hasattr(response, 'content') else str(response)
            else:
                answer = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            elapsed_time = time.time() - start_time

            print(f"  ë‹µë³€: {answer[:100]}...")
            print(f"  ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            print(f"  ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(docs)}ê°œ")

    elif args.mode == 'web':
        # ì›¹ UI ëª¨ë“œ
        print("Streamlit ì›¹ UIë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ë¡œ ì ‘ì†í•˜ì„¸ìš”.")
        print("\nì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")

        import subprocess
        subprocess.run(["streamlit", "run", "demo.py"])

    print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()