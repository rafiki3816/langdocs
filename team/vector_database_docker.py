"""Docker ì»¨í…Œì´ë„ˆ í™˜ê²½ì„ ìœ„í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë“ˆ
ChromaDB ì„œë²„ì™€ ì—°ë™í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸"""

import os
from typing import List, Dict, Any, Optional
from pathlib import Path

import chromadb
from chromadb.config import Settings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain_core.embeddings import Embeddings

from llm import get_embeddings


class DockerVectorDatabase:
    """Docker ChromaDB ì„œë²„ì™€ ì—°ë™í•˜ëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(
        self,
        host: str = None,
        port: int = 8000,
        collection_name: str = "langchain_docs",
        embedding_model: str = "solar-embedding-1-large"
    ):
        """
        DockerVectorDatabase ì´ˆê¸°í™”

        Args:
            host: ChromaDB ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ CHROMA_HOST ë˜ëŠ” localhost)
            port: ChromaDB ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
        """
        # í˜¸ìŠ¤íŠ¸ ì„¤ì • (Docker í™˜ê²½ ìë™ ê°ì§€)
        self.host = host or os.getenv("CHROMA_HOST", "localhost")
        self.port = port or int(os.getenv("CHROMA_PORT", "8000"))
        self.collection_name = collection_name

        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = chromadb.HttpClient(
            host=self.host,
            port=self.port,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )

        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        self.embeddings = self._get_embedding_model(embedding_model)
        self.vectorstore = None

        print(f"ChromaDB ì„œë²„ ì—°ê²°: {self.host}:{self.port}")

    def _get_embedding_model(self, model_name: str) -> Embeddings:
        """
        ì„ë² ë”© ëª¨ë¸ ì„ íƒ

        Args:
            model_name: ì„ë² ë”© ëª¨ë¸ ì´ë¦„

        Returns:
            Embeddings ì¸ìŠ¤í„´ìŠ¤
        """
        if model_name.startswith("solar"):
            # Upstage Solar Embedding
            return get_embeddings(model=model_name)
        elif model_name == "ko-sbert-multitask":
            # í•œêµ­ì–´ SBERT (sentence-transformers í•„ìš”)
            try:
                from langchain_community.embeddings import HuggingFaceEmbeddings
                return HuggingFaceEmbeddings(
                    model_name="jhgan/ko-sbert-multitask",
                    model_kwargs={'device': 'cpu'},
                    encode_kwargs={'normalize_embeddings': True}
                )
            except ImportError:
                print("sentence-transformers ì„¤ì¹˜ í•„ìš”: pip install sentence-transformers")
                return get_embeddings()  # fallback to solar
        else:
            # ê¸°ë³¸ê°’: Solar Embedding
            return get_embeddings()

    def init_vectorstore(self, reset: bool = False) -> Chroma:
        """
        ë²¡í„° ì €ì¥ì†Œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            reset: Trueì¼ ê²½ìš° ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±

        Returns:
            Chroma ë²¡í„° ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤
        """
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (reset=Trueì¸ ê²½ìš°)
        if reset:
            try:
                self.client.delete_collection(name=self.collection_name)
                print(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {self.collection_name}")
            except Exception as e:
                print(f"ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨ (ì—†ì„ ìˆ˜ ìˆìŒ): {e}")

        # Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        self.vectorstore = Chroma(
            client=self.client,
            collection_name=self.collection_name,
            embedding_function=self.embeddings
        )

        print(f"ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ: {self.collection_name}")

        # ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
        try:
            collection = self.client.get_collection(self.collection_name)
            count = collection.count()
            print(f"í˜„ì¬ ë¬¸ì„œ ìˆ˜: {count}")
        except:
            print("ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ ìƒì„±ë¨")

        return self.vectorstore

    def add_documents(
        self,
        documents: List[Document],
        batch_size: int = 100,
        show_progress: bool = True
    ) -> List[str]:
        """
        ë¬¸ì„œë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€í•©ë‹ˆë‹¤.

        Args:
            documents: ì¶”ê°€í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€

        Returns:
            ì¶”ê°€ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸
        """
        if not self.vectorstore:
            self.init_vectorstore()

        all_ids = []
        total_docs = len(documents)

        print(f"ì´ {total_docs}ê°œ ë¬¸ì„œ ì¶”ê°€ ì¤‘...")

        for i in range(0, total_docs, batch_size):
            batch = documents[i:i + batch_size]

            if show_progress:
                progress = min(i + batch_size, total_docs)
                print(f"ì§„í–‰ë¥ : {progress}/{total_docs} ({progress*100//total_docs}%)")

            try:
                ids = self.vectorstore.add_documents(batch)
                all_ids.extend(ids)
            except Exception as e:
                print(f"ë°°ì¹˜ ì¶”ê°€ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ê°œë³„ ì²˜ë¦¬
                for doc in batch:
                    try:
                        doc_id = self.vectorstore.add_documents([doc])
                        all_ids.extend(doc_id)
                    except Exception as e2:
                        print(f"ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e2}")

        print(f"ì™„ë£Œ: {len(all_ids)}ê°œ ë¬¸ì„œ ì¶”ê°€ë¨")
        return all_ids

    def search(
        self,
        query: str,
        k: int = 5,
        filter: Dict[str, Any] = None,
        search_type: str = "similarity"
    ) -> List[Document]:
        """
        ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            filter: ë©”íƒ€ë°ì´í„° í•„í„°
            search_type: ê²€ìƒ‰ íƒ€ì… ("similarity", "mmr")

        Returns:
            ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.vectorstore:
            self.init_vectorstore()

        if search_type == "mmr":
            # Maximum Marginal Relevance
            results = self.vectorstore.max_marginal_relevance_search(
                query=query,
                k=k,
                filter=filter
            )
        else:
            # ê¸°ë³¸: ìœ ì‚¬ë„ ê²€ìƒ‰
            results = self.vectorstore.similarity_search(
                query=query,
                k=k,
                filter=filter
            )

        return results

    def get_statistics(self) -> Dict[str, Any]:
        """
        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        stats = {
            "host": self.host,
            "port": self.port,
            "collection_name": self.collection_name,
            "embedding_model": self.embeddings.__class__.__name__
        }

        try:
            collection = self.client.get_collection(self.collection_name)
            stats["document_count"] = collection.count()

            # ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            sample = collection.peek(limit=1)
            if sample and sample.get("metadatas"):
                stats["sample_metadata_keys"] = list(sample["metadatas"][0].keys())
        except Exception as e:
            stats["error"] = str(e)

        return stats

    def health_check(self) -> bool:
        """
        ChromaDB ì„œë²„ í—¬ìŠ¤ì²´í¬

        Returns:
            ì„œë²„ê°€ ì •ìƒì´ë©´ True
        """
        try:
            # heartbeat API í˜¸ì¶œ
            self.client.heartbeat()
            return True
        except Exception as e:
            print(f"ChromaDB ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def backup_collection(self, backup_path: str = "./backups"):
        """
        ì»¬ë ‰ì…˜ì„ ë¡œì»¬ íŒŒì¼ë¡œ ë°±ì—…

        Args:
            backup_path: ë°±ì—… ì €ì¥ ê²½ë¡œ
        """
        Path(backup_path).mkdir(parents=True, exist_ok=True)

        try:
            collection = self.client.get_collection(self.collection_name)
            data = collection.get()

            import json
            from datetime import datetime

            backup_file = Path(backup_path) / f"{self.collection_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"ë°±ì—… ì™„ë£Œ: {backup_file}")
        except Exception as e:
            print(f"ë°±ì—… ì‹¤íŒ¨: {e}")

    def restore_collection(self, backup_file: str):
        """
        ë°±ì—… íŒŒì¼ì—ì„œ ì»¬ë ‰ì…˜ ë³µì›

        Args:
            backup_file: ë°±ì—… íŒŒì¼ ê²½ë¡œ
        """
        import json

        try:
            with open(backup_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # ì»¬ë ‰ì…˜ ì¬ìƒì„±
            self.init_vectorstore(reset=True)

            # ë°ì´í„° ë³µì›
            if data.get("documents"):
                documents = []
                for i, doc_text in enumerate(data["documents"]):
                    metadata = data["metadatas"][i] if i < len(data["metadatas"]) else {}
                    doc = Document(page_content=doc_text, metadata=metadata)
                    documents.append(doc)

                self.add_documents(documents)
                print(f"ë³µì› ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")
        except Exception as e:
            print(f"ë³µì› ì‹¤íŒ¨: {e}")


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_docker_vector_db(
    host: str = None,
    collection_name: str = "langchain_docs",
    reset: bool = False
) -> DockerVectorDatabase:
    """
    Docker í™˜ê²½ì˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Args:
        host: ChromaDB ì„œë²„ í˜¸ìŠ¤íŠ¸
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        reset: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì—¬ë¶€

    Returns:
        DockerVectorDatabase ì¸ìŠ¤í„´ìŠ¤
    """
    vdb = DockerVectorDatabase(
        host=host,
        collection_name=collection_name
    )

    # í—¬ìŠ¤ì²´í¬
    if not vdb.health_check():
        raise ConnectionError("ChromaDB ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    vdb.init_vectorstore(reset=reset)
    return vdb


def migrate_local_to_docker(
    local_persist_dir: str = "./data/chroma_db",
    docker_host: str = "localhost",
    collection_name: str = "langchain_docs"
):
    """
    ë¡œì»¬ ChromaDBë¥¼ Docker ChromaDBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

    Args:
        local_persist_dir: ë¡œì»¬ ChromaDB ë””ë ‰í† ë¦¬
        docker_host: Docker ChromaDB í˜¸ìŠ¤íŠ¸
        collection_name: ëŒ€ìƒ ì»¬ë ‰ì…˜ ì´ë¦„
    """
    from vector_database import VectorDatabase

    print("ë¡œì»¬ ë°ì´í„° ë¡œë“œ ì¤‘...")
    local_vdb = VectorDatabase(persist_directory=local_persist_dir)
    local_vdb.init_vectorstore()

    # ë¡œì»¬ì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (ì œí•œì )
    # ChromaDBëŠ” ì§ì ‘ì ì¸ ì „ì²´ ë¬¸ì„œ ì¶”ì¶œì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
    # ë³„ë„ ë°±ì—…/ë³µì› ë©”ì»¤ë‹ˆì¦˜ í•„ìš”

    print("Docker ChromaDBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜...")
    docker_vdb = create_docker_vector_db(
        host=docker_host,
        collection_name=collection_name,
        reset=True
    )

    print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    return docker_vdb


if __name__ == "__main__":
    # ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    print("=" * 60)
    print("Docker Vector Database ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # Docker ChromaDB ì—°ê²° í…ŒìŠ¤íŠ¸
    vdb = DockerVectorDatabase()

    # í—¬ìŠ¤ì²´í¬
    if vdb.health_check():
        print("âœ… ChromaDB ì„œë²„ ì •ìƒ")
    else:
        print("âŒ ChromaDB ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
        print("\nDocker Composeë¡œ ChromaDB ì‹œì‘:")
        print("  docker-compose up -d chromadb")
        exit(1)

    # ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
    vdb.init_vectorstore()

    # í†µê³„ ì¶œë ¥
    stats = vdb.get_statistics()
    print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ!")